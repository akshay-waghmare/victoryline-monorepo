# VictoryLine - Live Cricket Score Application

A comprehensive live cricket score application built with a modern tech stack, combining real-time data scraping, secure backend APIs, and an interactive frontend.

## ğŸ—ï¸ Architecture

This monorepo contains three main applications that work together:

```
victoryline-monorepo/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ frontend/     # Angular-based web application
â”‚   â”œâ”€â”€ backend/      # Spring Boot REST API with JWT authentication
â”‚   â””â”€â”€ scraper/      # Python-based cricket data scraper
â””â”€â”€ packages/         # Shared utilities (future)
```

### Components

#### ğŸ¨ Frontend (`apps/frontend`)
- **Tech Stack**: Angular, TypeScript, Bootstrap
- **Branch**: `adv` (production-ready)
- **Features**:
  - Real-time cricket score updates
  - User authentication & authorization
  - Responsive design for mobile/desktop
  - Match details and player statistics

#### ğŸ” Backend (`apps/backend`)
- **Tech Stack**: Spring Boot, Java, JWT, MySQL
- **Branch**: `production`
- **Features**:
  - RESTful API endpoints
  - JWT-based authentication
  - Role-based access control (RBAC)
  - Match and user data management
  - Secure API for frontend consumption

#### ğŸ•·ï¸ Scraper (`apps/scraper`)
- **Tech Stack**: Python, Crawlee, Scrapy
- **Branch**: `production`
- **Features**:
  - Real-time cricket match data scraping
  - Ball-by-ball data collection
  - Player statistics aggregation
  - Data processing and storage
  - API service for scraped data

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** >= 14.0.0
- **pnpm** >= 8.0.0 (recommended) or npm
- **Python** >= 3.8
- **Java** >= 11
- **Maven** >= 3.6
- **MySQL** >= 5.7 (for backend)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/akshay-waghmare/victoryline-monorepo.git
cd victoryline-monorepo
```

2. **Install all dependencies**
```bash
npm run install:all
```

Or install individually:

```bash
# Frontend dependencies
cd apps/frontend
npm install

# Backend dependencies
cd apps/backend
mvn clean install

# Scraper dependencies
cd apps/scraper
pip install -r requirements.txt
```

### Development

Run each service in separate terminals:

```bash
# Terminal 1 - Frontend (runs on http://localhost:4200)
npm run dev:frontend

# Terminal 2 - Backend (runs on http://localhost:8080)
npm run dev:backend

# Terminal 3 - Scraper (runs on http://localhost:5000)
npm run dev:scraper
```

### Build

Build all applications for production:

```bash
npm run build:all
```

Or build individually:

```bash
npm run frontend:build
npm run backend:build
```

### Testing

Run all tests:

```bash
npm run test:all
```

Or test individually:

```bash
npm run frontend:test
npm run backend:test
npm run scraper:test
```

## ğŸ“¦ Project Structure

### Frontend Structure
```
apps/frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/          # Angular components, services, guards
â”‚   â”œâ”€â”€ assets/       # Static assets
â”‚   â””â”€â”€ environments/ # Environment configurations
â”œâ”€â”€ angular.json
â””â”€â”€ package.json
```

### Backend Structure
```
apps/backend/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â”œâ”€â”€ java/     # Spring Boot application code
â”‚       â””â”€â”€ resources/# Configuration files
â”œâ”€â”€ pom.xml
â””â”€â”€ Dockerfile
```

### Scraper Structure
```
apps/scraper/
â”œâ”€â”€ src/              # Python scraper modules
â”œâ”€â”€ tests/            # Test files
â”œâ”€â”€ requirements.txt
â””â”€â”€ run_server.py     # API server
```

## ğŸ”§ Configuration

### Frontend Configuration
- Update `apps/frontend/src/environments/environment.ts` with your API URLs

### Backend Configuration
- Update `apps/backend/src/main/resources/application.properties` with database credentials

### Scraper Configuration
- Update scraper configuration in `apps/scraper/src/config.py`

## ğŸ³ Docker Support

Each application includes Dockerfile for containerization:

```bash
# Build and run with Docker Compose
docker-compose up --build
```

## ğŸŒ¿ Branch Strategy

- **Frontend**: `adv` branch contains latest stable code
- **Backend**: `production` branch contains latest stable code
- **Scraper**: `production` branch contains latest stable code

## ğŸ“ Available Scripts

| Command | Description |
|---------|-------------|
| `npm run dev:frontend` | Start frontend development server |
| `npm run dev:backend` | Start backend development server |
| `npm run dev:scraper` | Start scraper API server |
| `npm run build:all` | Build all applications |
| `npm run test:all` | Run all tests |
| `npm run install:all` | Install all dependencies |

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the ISC License.

## ğŸ‘¨â€ğŸ’» Author

**Akshay Waghmare**

## ğŸ”— Original Repositories

This monorepo combines code from:
- [crex_scraper_python](https://github.com/akshay-waghmare/crex_scraper_python)
- [jwt-example-role-based](https://github.com/akshay-waghmare/jwt-example-role-based)
- [laundry-app](https://github.com/akshay-waghmare/laundry-app)

## ğŸ“ Support

For issues and questions, please open an issue in the GitHub repository.

---

**Note**: Make sure to configure environment variables and database connections before running the applications.
